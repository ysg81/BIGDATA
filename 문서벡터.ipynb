{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "문서벡터",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONHqKvPcTLBD01YbI7G5xA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysg81/BIG_DATA/blob/main/%EB%AC%B8%EC%84%9C%EB%B2%A1%ED%84%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTmkGl6YasOb",
        "outputId": "d6235e07-7892-481d-d96d-9cfc3ff9c920"
      },
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "import csv\n",
        "import ast\n",
        "import copy\n",
        "import logging\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpEVcSOFa0vB"
      },
      "source": [
        "# 형태소 분해 된 파일 읽는 코드\n",
        " \n",
        "f = open('/gdrive/My Drive/빅데이터/record3_NLTK.csv', 'r', encoding='utf-8')\n",
        "rdr = csv.reader(f)\n",
        "\n",
        "morpheme_separatied_datas = []\n",
        "morpheme_separatied_data_dic = {}\n",
        "\n",
        "morpheme_separatied_type = 5\n",
        "\n",
        "is_content = False\n",
        "ind = 0\n",
        "for line in rdr:\n",
        "    if(is_content):\n",
        "        morpheme_separatied_datas.append([line[0], line[1], line[2], line[3], ast.literal_eval(line[morpheme_separatied_type])] )\n",
        "        morpheme_separatied_data_dic[line[0]] = ind\n",
        "        ind += 1\n",
        "    is_content = True\n",
        " \n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHSbGY-usGRG"
      },
      "source": [
        "# 문서벡터 모델을 만드는 코드 \n",
        "\n",
        "TRAIN_documents = [TaggedDocument(words=text, tags=[tags]) for tags, x1, x2, x3, text in morpheme_separatied_datas]\n",
        "\n",
        "class callback(CallbackAny2Vec):\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "    def on_epoch_end(self, model):\n",
        "        self.epoch += 1\n",
        "        print('epoch {}'.format(self.epoch))\n",
        "        \n",
        "vector_size = 256\n",
        "model = Doc2Vec(TRAIN_documents, vector_size=vector_size, window=3, epochs=80, min_count=0, workers=4, callbacks=[callback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38ipqewNvSbB"
      },
      "source": [
        "# 만든 모델을 저장하는 코드\n",
        "model.save('/gdrive/My Drive/빅데이터/summary_model.doc2vec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zQDKwm_vSKS"
      },
      "source": [
        "# 저장한 모델을 불러오는 코드\n",
        "model = Doc2Vec.load('/gdrive/My Drive/빅데이터/summary_model.doc2vec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeeB67qGv1ec"
      },
      "source": [
        "# 만든 모델로 트레이닝 데이터를 다시 가공하는 코드\n",
        "\n",
        "doc_vectorlized_datas = copy.deepcopy(morpheme_separatied_datas)\n",
        "\n",
        "for i in range(0,len(doc_vectorlized_datas)):\n",
        "    if(i%100 == 0): print(i)\n",
        "    trained_doc_vec = model.docvecs[doc_vectorlized_datas[i][0]]\n",
        "    inferred_doc_vec = model.infer_vector(doc_vectorlized_datas[i][4])\n",
        "    doc_vectorlized_datas[i].append(inferred_doc_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtN0Y3RW0HgI"
      },
      "source": [
        "# 가공된 트레이닝 데이터를 csv 파일로 저장하는 코드\n",
        "\n",
        "with open('listfile.csv', 'w', newline='') as f: \n",
        "    writer = csv.writer(f)\n",
        "    for i in range(len(doc_vectorlized_datas)):\n",
        "        if(i%100 == 0): print(i)\n",
        "        writer.writerow(doc_vectorlized_datas)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BXDwWkuwzJl"
      },
      "source": [
        "# 형태소분해 된 문장 중 가장 비슷한 문장 id를 찾는 코드\n",
        "\n",
        "\n",
        "def finding_similar(new_document, count = 1):\n",
        "\n",
        "    inferred_v = model_loaded.infer_vector(new_document)\n",
        "    model.docvecs.init_sims()\n",
        "    return model_loaded.docvecs.most_similar([inferred_v], topn=count)\n",
        "\n",
        "# [[문서id, 유사도]...count개]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}